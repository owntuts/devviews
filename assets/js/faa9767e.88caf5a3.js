"use strict";(self.webpackChunkinterviewdev=self.webpackChunkinterviewdev||[]).push([[7245],{3905:function(e,t,n){n.d(t,{Zo:function(){return m},kt:function(){return k}});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var p=r.createContext({}),l=function(e){var t=r.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},m=function(e){var t=l(e.components);return r.createElement(p.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},f=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,p=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),c=l(n),f=a,k=c["".concat(p,".").concat(f)]||c[f]||u[f]||i;return n?r.createElement(k,o(o({ref:t},m),{},{components:n})):r.createElement(k,o({ref:t},m))}));function k(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=f;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s[c]="string"==typeof e?e:a,o[1]=s;for(var l=2;l<i;l++)o[l]=n[l];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}f.displayName="MDXCreateElement"},31145:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return o},default:function(){return u},frontMatter:function(){return i},metadata:function(){return s},toc:function(){return l}});var r=n(83117),a=(n(67294),n(3905));const i={sidebar_position:1e3,sidebar_label:"Kafka Partition",title:"Kafka Partition",tags:["Kafka Knowledge"]},o=void 0,s={unversionedId:"kafka/hero/partition",id:"kafka/hero/partition",title:"Kafka Partition",description:"Topic & Partitioning in Kafka",source:"@site/docs/kafka/hero/partition.md",sourceDirName:"kafka/hero",slug:"/kafka/hero/partition",permalink:"/devviews/interviews/kafka/hero/partition",draft:!1,editUrl:"https://github.com/owntuts/devviews/edit/main/docs/kafka/hero/partition.md",tags:[{label:"Kafka Knowledge",permalink:"/devviews/interviews/tags/kafka-knowledge"}],version:"current",sidebarPosition:1e3,frontMatter:{sidebar_position:1e3,sidebar_label:"Kafka Partition",title:"Kafka Partition",tags:["Kafka Knowledge"]},sidebar:"kafkaInterviewSidebar",previous:{title:"Kafka kstream vs ktable",permalink:"/devviews/interviews/kafka/hero/kstreamvsktable"},next:{title:"Kafka Pub/Sub Example",permalink:"/devviews/interviews/kafka/hero/pub-sub-strem-example"}},p={},l=[{value:"How it works",id:"how-it-works",level:3}],m={toc:l},c="wrapper";function u(e){let{components:t,...i}=e;return(0,a.kt)(c,(0,r.Z)({},m,i,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("details",{open:!0},(0,a.kt)("summary",null,(0,a.kt)("h5",null,"Topic & Partitioning in Kafka")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"A topic")," is like ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"a log of events")),". "),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"First, they are ",(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("em",{parentName:"strong"},"append only")),": When you write a new message into a log, it always goes on the end. "),(0,a.kt)("li",{parentName:"ul"},"Second, they can only be ",(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("em",{parentName:"strong"},"read by seeking an arbitrary offset"))," in the log, then by scanning sequential log entries. "),(0,a.kt)("li",{parentName:"ul"},"Third, events in the log are ",(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("em",{parentName:"strong"},"immutable\u2014once something has happened")),", it is exceedingly difficult to make it un-happen."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"A partition")," is a unit of distribution and replication for topics. ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"Topics can have one or more partitions")),", each of which is essentially an ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"ordered, immutable sequence of records")),". Partitions allow for the parallelism of data ingestion from producers and parallel processing of data by consumer groups."))),(0,a.kt)("h3",{id:"how-it-works"},"How it works"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"A producer sends a message to a Kafka topic"),(0,a.kt)("li",{parentName:"ol"},"The message is ",(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("em",{parentName:"strong"},"written to the end"))," of the partition's log & also ",(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("em",{parentName:"strong"},"assigned a unique offset"))," (which is a sequential id number) that represents the message's position in the partition. "),(0,a.kt)("li",{parentName:"ol"},"Consumers can then read data from these partitions by ",(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("em",{parentName:"strong"},"specifying the topic and partition, as well as the offset"))," from which they want to start reading.")),(0,a.kt)("p",null,"Here's an example to explain how partitions work in Kafka:"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Kafka Partition",src:n(36608).Z,width:"1653",height:"545"})),(0,a.kt)("p",null,'Imagine a Kafka topic "User_Logins" with two partitions (P1, P2) and two consumers in the same consumer group. Each consumer wants to read data from the "User_Logins" topic. When a producer sends a message to the topic, it is written to one of the partitions (for example, P1). All the consumers in the same consumer group will read messages from all the partitions in the topic, but ',(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"each consumer will only read messages from one partition at a time"))," to ensure parallelism (ex, consumer group A)."),(0,a.kt)("p",null,"If the number of consumers is less than the number of partitions, ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"some consumers may fetch messages from multiple partitions"))," (ex, consumer group B). By increasing the number of partitions in a topic, it is possible to increase the throughput and parallelism of data ingestion and processing.")))}u.isMDXComponent=!0},36608:function(e,t,n){t.Z=n.p+"assets/images/partition-4d239924c1e39e22ffc74ab719ec1862.png"}}]);