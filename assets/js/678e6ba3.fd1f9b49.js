"use strict";(self.webpackChunkinterviewdev=self.webpackChunkinterviewdev||[]).push([[7571],{3905:function(e,t,r){r.d(t,{Zo:function(){return c},kt:function(){return f}});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var u=n.createContext({}),l=function(e){var t=n.useContext(u),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},c=function(e){var t=l(e.components);return n.createElement(u.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,u=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=l(r),d=a,f=p["".concat(u,".").concat(d)]||p[d]||m[d]||o;return r?n.createElement(f,i(i({ref:t},c),{},{components:r})):n.createElement(f,i({ref:t},c))}));function f(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=d;var s={};for(var u in t)hasOwnProperty.call(t,u)&&(s[u]=t[u]);s.originalType=e,s[p]="string"==typeof e?e:a,i[1]=s;for(var l=2;l<o;l++)i[l]=r[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}d.displayName="MDXCreateElement"},18258:function(e,t,r){r.r(t),r.d(t,{assets:function(){return u},contentTitle:function(){return i},default:function(){return m},frontMatter:function(){return o},metadata:function(){return s},toc:function(){return l}});var n=r(83117),a=(r(67294),r(3905));const o={sidebar_position:1e3,sidebar_label:"list of common stream operations",title:"list of common stream operations",tags:["Kafka Knowledge"]},i=void 0,s={unversionedId:"kafka/hero/common-stream",id:"kafka/hero/common-stream",title:"list of common stream operations",description:"List of common stream operations",source:"@site/docs/kafka/hero/common-stream.md",sourceDirName:"kafka/hero",slug:"/kafka/hero/common-stream",permalink:"/devviews/interviews/kafka/hero/common-stream",draft:!1,editUrl:"https://github.com/owntuts/devviews/edit/main/docs/kafka/hero/common-stream.md",tags:[{label:"Kafka Knowledge",permalink:"/devviews/interviews/tags/kafka-knowledge"}],version:"current",sidebarPosition:1e3,frontMatter:{sidebar_position:1e3,sidebar_label:"list of common stream operations",title:"list of common stream operations",tags:["Kafka Knowledge"]},sidebar:"kafkaInterviewSidebar",previous:{title:"Kafka Architecture",permalink:"/devviews/interviews/kafka/hero/architecture"},next:{title:"Kafka Implement Cluster",permalink:"/devviews/interviews/kafka/hero/implement-cluster"}},u={},l=[],c={toc:l},p="wrapper";function m(e){let{components:t,...r}=e;return(0,a.kt)(p,(0,n.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("details",{open:!0},(0,a.kt)("summary",null,(0,a.kt)("h5",null,"List of common stream operations")),(0,a.kt)("p",null,"Kafka Streams provides a high-level DSL (Domain Specific Language) that lets you define common stream processing operations such as ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"filtering, mapping, joining, or aggregating"))," on data streams."),(0,a.kt)("p",null,"Here are some examples of these operations:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"filter"),": Filters records from a stream or table based on a predicate function. For example, if we have a stream of messages with keys and values as strings, we can filter out records that have a null value or a negative key:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'// Create a stream from a Kafka topic\nKStream<String, String> input = builder.stream("input-topic");\n\n// Filter out records with null value or negative key\nKStream<String, String> output = input.filter((key, value) -> value != null && !key.startsWith("-"));\n\n// Send the output stream to another Kafka topic\noutput.to("output-topic");\n')),(0,a.kt)("p",null,"The input and output of this operation are both streams."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"map"),": Transforms each record from a stream or table by applying a mapper function. For example, if we have a stream of messages with keys and values as strings, we can map a record's value to its length or its key to its hash code:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'// Create a stream from a Kafka topic\nKStream<String, String> input = builder.stream("input-topic");\n\n// Map the value to its length and the key to its hash code\nKStream<Integer, Integer> output = input.map((key, value) -> new KeyValue<>(key.hashCode(), value.length()));\n\n// Send the output stream to another Kafka topic\noutput.to("output-topic");\n')),(0,a.kt)("p",null,"The input and output of this operation are both streams."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"join"),": Joins two streams or tables based on a common key and a joiner function. For example, if we have a stream of customer orders and a table of customer profiles, we can join them by customer ID and enrich the order records with profile information:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'// Create a stream from a Kafka topic\nKStream<String, Order> orders = builder.stream("orders-topic");\n\n// Create a table from another Kafka topic\nKTable<String, Profile> profiles = builder.table("profiles-topic");\n\n// Join the stream and the table by customer ID and add profile information to order records\nKStream<String, EnrichedOrder> output = orders.join(profiles,\n    (order, profile) -> new EnrichedOrder(order.getId(), order.getAmount(), profile.getName(), profile.getAddress()));\n\n// Send the output stream to another Kafka topic\noutput.to("output-topic");\n')),(0,a.kt)("p",null,"The input of this operation is a stream and a table, and the output is a stream."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"aggregate"),": Aggregates records from a stream or table by grouping them by key and applying an aggregator function. For example, if we have a stream of clicks by user ID and URL, we can aggregate them by user ID and count the number of clicks per user:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'// Create a stream from a Kafka topic\nKStream<String, Click> clicks = builder.stream("clicks-topic");\n\n// Aggregate the clicks by user ID and count the number of clicks per user\nKTable<String, Long> output = clicks.groupByKey().count();\n\n// Send the output table to another Kafka topic\noutput.toStream().to("output-topic");\n')),(0,a.kt)("p",null,"The input of this operation is a stream, and the output is a table."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"strong"},"join(KStream, ValueJoiner, JoinWindows)")),": This operation joins two KStreams based on their keys and a window specification. It returns a new KStream that contains pairs of values from both streams for each matching key within the window. For example, if you have two streams of user clicks and purchases, you can join them to get pairs of clicks and purchases for each user within a certain time interval.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'// Assume we have two KStreams of user clicks and purchases\nKStream<String, String> clicks = ...; // key: user, value: click\nKStream<String, String> purchases = ...; // key: user, value: purchase\n\n// Define a join window of 10 seconds\nJoinWindows joinWindow = JoinWindows.of(Duration.ofSeconds(10));\n\n// Define a value joiner that concatenates the values\nValueJoiner<String, String, String> valueJoiner = (click, purchase) -> click + " -> " + purchase;\n\n// Join the two streams on the user key and print the result\nKStream<String, String> joined = clicks.join(purchases, valueJoiner, joinWindow);\njoined.foreach((user, value) -> System.out.println(user + ": " + value));\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Input:\n  clicks: (user1, click1), (user2, click2), (user1, click3), (user3, click4)\n  purchases: (user1, purchase1), (user2, purchase2), (user3, purchase3), (user1, purchase4)\nOutput:\n  user1: click1 -> purchase1 user2: click2 -> purchase2 user1: click3 -> purchase4 user3: click4 -> purchase3\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"strong"},"groupBy")),": This operation splits a stream into sub-streams based on a key function. It returns a KGroupedStream object that can be further aggregated or windowed. For example, if you have a stream of words, you can group them by their length to get sub-streams of words with the same length.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'// Assume we have a KStream of words\nKStream<String, String> words = ...; // key: null, value: word\n\n// Define a key function that returns the word length\nKeyValueMapper<String, String, Integer> keyFunction = (key, word) -> word.length();\n\n// Group the words by their length and print the result\nKGroupedStream<Integer, String> grouped = words.groupBy(keyFunction);\ngrouped.foreach((length, word) -> System.out.println(length + ": " + word));\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'Input:\n  words: "hello", "world", "kafka", "streams", "java"\nOutput:\n  grouped: 5 -> ("hello", "world", "kafka"), 6 -> ("streams"), 4 -> ("java")\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"strong"},"reduce")),": This operation applies a reducer function to each sub-stream of a KGroupedStream and returns a KTable that contains the latest reduced value for each key. For example, if you have a KGroupedStream of user ratings for movies, you can reduce them to get the average rating for each movie\xb3.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'// Assume we have a KGroupedStream of user ratings for movies\nKGroupedStream<String, Integer> ratings = ...; // key: movie, value: rating\n\n// Define a reducer function that computes the average rating\nReducer<Integer> reducer = (oldValue, newValue) -> (oldValue + newValue) / 2;\n\n// Reduce the ratings by movie and print the result\nKTable<String, Integer> reduced = ratings.reduce(reducer);\nreduced.toStream().foreach((movie, rating) -> System.out.println(movie + ": " + rating));\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Input:\n  ratings: movie1 -> (user1, 4), movie2 -> (user2, 5), movie1 -> (user3, 3), movie2 -> (user4, 4), movie1 -> (user5, 5)\nOutput:\n  reduced: movie1 -> 4, movie2 -> 4.5\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"strong"},"windowedBy")),": This operation applies a window specification to a KGroupedStream and returns a TimeWindowedKStream or SessionWindowedKStream that contains the records for each key within the window. For example, if you have a KGroupedStream of user actions on a website, you can window them by time to get the actions for each user within a certain time interval.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-java"},'// Assume we have a KGroupedStream of user actions on a website\nKGroupedStream<String, String> actions = ...; // key: user, value: action\n\n// Define a time window of 10 seconds\nTimeWindows timeWindow = TimeWindows.of(Duration.ofSeconds(10));\n\n// Window the actions by user and time and print the result\nTimeWindowedKStream<String, String> windowed = actions.windowedBy(timeWindow);\nwindowed.foreach((windowedKey, action) -> {\n  String user = windowedKey.key();\n  Window window = windowedKey.window();\n  System.out.println(window + ": " + user + ": " + action);\n  });\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'Input:\n  actions: user1 -> "login", user2 -> "search", user1 -> "view", user3 -> "login", user2 -> "buy", user1 -> "logout"\nOutput:\n  windowed: [0s-10s] -> user1 -> ("login", "view"), user2 -> ("search"), user3 -> ("login")\n            [10s-20s] -> user2 -> ("buy"), user1 -> ("logout")\n'))))}m.isMDXComponent=!0}}]);